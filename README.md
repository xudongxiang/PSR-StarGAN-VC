<table style="width:100%">
  <tr>
    <td align="center">
    <a href="https://www.ultralytics.com" target="_blank">
    <img src="https://storage.googleapis.com/ultralytics/logo/logoname1000.png" width="160"></a>
      <img src="https://github.com/xudongxiang/demo/blob/master/images/G-D-C-5-7.jpg">
          <a href="https://itunes.apple.com/app/id1452689527" target="_blank">
    <img src="https://user-images.githubusercontent.com/26833433/50044365-9b22ac00-0082-11e9-862f-e77aee7aa7b0.png" width="180"></a>
  </tr>
</table>
# Converted speech of PSR-StarGAN-VC
* This repository storages converted speech of PSR-StarGAN-VC. If you want to get more converted speech, please contact with me by email.  
* In order to compare converted speech by PSR-StarGAN-VC with official demo of StarGAN-VC, we need to select same speaker as they select. Experiment are carried on four speakers (SF1, SF2, SM1, and SM2) following the two systems again.
# Demo of PSR-StarGAN-VC
* The demo of PSR-StarGAN-VC can be found in ![`PSR-StarGAN-VC`](http://htmlpreview.github.io/?https://github.com/xudongxiang/demo/blob/master/PSR-StarGAN-VC.html) . If you can't open this website, please utilize vpn to connect or ![download](https://github.com/xudongxiang/demo/blob/master/demo-four.zip) to local and compare it with StarGAN-VC or StarGAN-VC2;<br>
* The official demo of StarGAN-VC can be found in ![StarGAN-VC](http://www.kecl.ntt.co.jp/people/kameoka.hirokazu/Demos/stargan-vc/);<br>
* You also can compare our proposed method PSR-StarGAN-VC with the newest method ![StarGAN-VC2](http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/stargan-vc2/index.html) by opening two windows. 

